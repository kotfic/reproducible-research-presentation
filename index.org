#+OPTIONS: toc:nil num:nil author:nil email:nil
#+REVEAL_TRANS: default
#+REVEAL_THEME: sky
#+REVEAL_ROOT: revealjs/
#+REVEAL_HLEVEL: 1

* Reproducible Research
open access, open data, open tools and metrics

* Introduction
Christopher Kotfila\\
PhD student - Information Science Department\\
College of Computing and Information\\
ckotfila@albany.edu \\
@kotfic
** Who Am I?
#+BEGIN_NOTES
Graduated last spring with an MSIS from here at UAlbany

Focused primarily on scholarly communication and open access

Professional background is as a software developer

Primarily working with open source tools and in the open source community

#+END_NOTES
** That's a long title
Are you really going to talk about all that in 30 minutes?

#+BEGIN_NOTES
So the answer of course is no.

This talk is going to focus on reproducible research

In particular I'm going to be talking about how tools that software developers have created 

can help to solve the so-called reporducibility crisis

#+END_NOTES

** Caveat 
#+BEGIN_QUOTE
"Release early, release often"[1]
#+END_QUOTE
 
#+BEGIN_HTML
<sup id="fn.1" style="font-size:18px;"> [1] Eric S. Raymond, The Cathedral and the Bazaar (1997) </sup>
#+END_HTML

#+BEGIN_NOTES
So there is a relatively well established philosophy in software development "Release early release often"

In software this means,  get your program out there as soon as possible and let people start giving you feedback

This presentation emerges from a relatively new interest in the topic 

Some of the ideas here are still a little rough,  but in true Open Source fashion,  I hope you'll help me refine them. 

#+END_NOTES
* An Example from personal experience
#+BEGIN_NOTES
So - I began working as a research assistant here at Albany at the beginning of this summer

The work I'm learning to do involves writing computer programs to to pull structured information out of unstructured medical discharge summaries.  

There are a lot of interesting and practical applications for work like this

tracking patient outcomes for instance

identifying systematic issues at hospitals or with health care processes - lots of stuff.

This is done primarily with natural language process tools (ie.  computer programs and processes) 

As an initial exercize I set out to reproduce a well performing system in a particular challenge that tried to identify whether patients had obesity based on the free-form text in their medical record.

#+END_NOTES
* The idea was...
** reproduce the system based on the description in the paper,

** try to identify systematic errors
** correct those errors
** publish in a prestigious journal
** get a tenure-track position at a respected university
** live happily ever afer

* So It turns out...
#+BEGIN_NOTES
So it turns out,  this wasn't really a great plan -

The system is unrecoverable, 

and sadly (for me at least) un-reproducible.

This is the experience that got me interested in the topic 

so lets talk a little more about some of the background

#+END_NOTES



* Reproducibility
#+BEGIN_NOTES
Fundimentally rooted in scientific skepticism. 

Findings may be interesting - but if they can't be reproduced by other researchers in normalalized settings 

Then those findings are suspect - they don't meet the "bar" of reproducibility

Which brings us to our first point:
#+END_NOTES

* Reproducibility creates Credibility 
#+BEGIN_NOTES
Reproducibility creates credibility

A lack of reproducibility introduces uncertainty. 

a sufficient lack of this kind of uncerteainty and you create a crisis of confidence in your findings
#+END_NOTES

* Reproducibility is about Communication
#+BEGIN_NOTES
Reproducibility emerges from communication of

Communication of  *Who* did *What* 

Communication of *How* they did it *When* it happend and *Why* it was done

#+END_NOTES

* Technology has enabled Reproducibility
#+BEGIN_NOTES
Technology has traditionally enabled reproducibility in science by improving our ability to communicate with eachother

Exibit A:
#+END_NOTES


* 
[[file:img/402px-1665_phil_trans_vol_i_title.png]]


* First Issue, First paragraph First sentence, 
#+BEGIN_QUOTE
"Whereas there is nothing more necessary for promoting the improvement of Philosophical Matters, than the communicating [... of] such things as are discovered or put in practice by others."  Henry Oldenburg 1665 
#+END_QUOTE

#+BEGIN_NOTES
From the very begining scholarly communication has been about communicating findings to others in a way that can be reproduced.
#+END_NOTES

* Modern Technologies have outpaced current mechanisms for Reproducibility
#+BEGIN_NOTES
Fast Forward - Computational science has enabled great advances in human knowledge - 

But historical mechanisms for distributing these new kinds of scientific findings are insufficient

Analysis and interpretation may still fit on 9 pages (not including references)

But the data, the systems, the code - these linger and die on servers in campus closets.

#+END_NOTES

* There are modern Technologies that can make Reproducibility easy again
#+BEGIN_NOTES
Thankfully technology can make reproducibility easy again

Not just rescuing code by uploading it to repositories

But by brining the entire research process out into the open
#+END_NOTES

* The Open Science Pipeline 
#+BEGIN_NOTES
Really, reproducible research is concerned with ALL the steps between a data source and a publiction. 

This means obtaining, scrubing, modeling, interpreting and presenting data. 

This doesn't HAVE to be in the context of an open data and open access 

BUT - in this context open reproducible research brings end-to-end transparency to the entire process.

#+END_NOTES
+ Open Data
+ Reproducible Research
+ Open Access

* 
#+BEGIN_QUOTE
“The idea is: An article about computational science in a scientific
publication is not the scholarship itself, it is merely advertising of the
scholarship. The actual scholarship is the complete ... set of
instructions [and data] which generated the figures.”
David Donoho, 1998.
#+END_QUOTE

#+BEGIN_NOTES
David Donoho is one of the reseachers over at Stanford who has been actively involved with the reproducibility movement for decades

As Donoho puts it:

The failure of current distribution mechanisms - 

both from a technical perspective,  and from a socio-cultural perspective have created a credebility crisis
#+END_NOTES

* A state of "Crisis"
#+REVEAL_HTML: <div style="font-size:16px">
+ 2012 Begley, C. Glenn and Ellis, Lee M. Drug development: Raise standards for preclinical cancer research, Nature
+ 2011 AAAS annual meeting: Workshop on the digitization of science
+ 2011 Applied mathematics perspectives workshop on reproducible research
+ 2011 SIAM conference on computational science & engineering workshop on verifiable, reproducible computational science.
+ 2011 SIAM geosciences workshop on reproducible science and open-source software in the geosciences
+ 2011 Research ethics in biostatistics: Invited panel discussion on the biostatistician’s role in reproducible research.
+ 2010 National science foundation workshop on changing the conduct of science inthe information age summary.
+ 2009 Yale Law School Round Table on Data and Code Sharing 
+ And many others...
#+REVEAL_HTML: </div>

#+BEGIN_NOTES
There has been a swath of conferences and papers in the last few years focusing on the "credibility crisis" that stems from reproducibility issues in the computational sciences

Not to mention a growing amount of attention from the popular media

proposed solutions run the gamit from technical implementations to to policy recommendations 

#+END_NOTES


* Some Proposed Solutions
+ [[http://runmycode.org/][RunMyCode.org]]
+ [[http://www.stat.uni-muenchen.de/~leisch/Sweave/][Sweave]]
+ [[https://openscienceframework.org/][Open Science Framework]]
+ [[http://www.stanford.edu/~vcs/Papers.html][Victoria Stodden's work]]
+ ...

#+BEGIN_NOTES
Of course there are many many more examples 

but what I'd like to humbly suggest here in this presentation,  

is that there are STRONG examples in the open source software development community

for how resolve the *technical* and *socio-cultural* aspects of the computational reproducibility problem.

#+END_NOTES


* Open Source Software Developers
#+BEGIN_NOTES
Reproducibility is (arguably) the number one concern of open source software developers.

As a software developer,  if the code i write and run on my system 

doesn't run on your system

my code is broken.

#+END_NOTES

* Software Developers are Tool Oriented
#+BEGIN_NOTES
Software developers are tool oriented kind of people

They build the software tools you use every day and they use highly specialized tools to do it

if theres a problem,  

the first thing a software developer thinks is "is there a tool that solves this problem already?"

The second thing they think is - "can I build a tool that solves this problem?"
#+END_NOTES

* Software
(is complicated)
#+BEGIN_NOTES
Software is complicated and historically trending TOWARDS more complexity,  not AWAY from it

But this complexity is just a problem - and so developers have done what developers know how to do

build software to solve the problem of managing software's growing complexity.
#+END_NOTES

* Reproducibility
(is complicated)
#+BEGIN_NOTES

#+END_NOTES

* Software Tools
(can ease that complexity)
#+BEGIN_NOTES
Tools can ease complexity,  and especially they can ease the complexity of the reproducibility problem. 

The success of an open software development project is BASED on its ability to be reproduced across many systems

open source software DEVELOPERS have produced tools that are optimized to ease this distribution.
#+END_NOTES

** Open Source Software Developers and Researchers 
(have a lot in common)
*** Highly specialized 
*** Experts in their area
*** Collaborate frequently
Usually working on teams that are \\
geographically disparate  \\ 
culturally diverse
*** Often Work in Silos 
*** Produce complex processes that 
+ obtain 
+ scrub
+ explore
+ model 
+ interpret
+ and display data


* Tools for Reproducible Research
#+BEGIN_NOTES
Because of the similarities between open source software developers and researchers many of these tools can be recast in light of the research process.
#+END_NOTES



* Source Control Management Systems
#+BEGIN_NOTES
The most germane tools I want to talk about are in the category of Source Control
#+END_NOTES
** Maybe you've seen this problem before
#+ATTR_REVEAL: :frag roll-in
Draft paper.docx \\
#+ATTR_REVEAL: :frag roll-in
Draft paper2.docx \\
#+ATTR_REVEAL: :frag roll-in
Draft paper2-old.docx \\
#+ATTR_REVEAL: :frag roll-in
Draft paper3-revisions-from-dla.docx \\
#+ATTR_REVEAL: :frag roll-in
Final submitted.docx  \\
#+ATTR_REVEAL: :frag roll-in
Final submitted revised.docx \\
#+BEGIN_NOTES
Keeping track of changes in a single document is hard

Keeping track of changes from a group of authors and reviewers in a single document is even harder

Magnify that difficulty by the thousands and sometimes tens of thousands of documents in an software development project

and you might as well pack up and go home
#+END_NOTES


** *Who* did *what*, *when* and *why*?
#+BEGIN_NOTES
The only way to manage this effectively is build a system that tracks WHO did WHAT WHEN, and most importaintly WHY.

Here is an example
#+END_NOTES
An Example of a [[https://github.com/kotfic/reproducible-research-presentation/commit/04ff60559adcf31f627f909c2cc4e00f1c564509]["Commit"]]

** Diffs and Patches
#+BEGIN_NOTES
Tracking this information in such excrutiating detail provides interesting possibilities

For one it allows you to pass the changes that you make to a document easily to someone else

Source Control Management systems will (mostly)  seamlessly integrate your changes into other people's copy of your document.

additionally this kind of specificity allows for profound archiving possibilities and provides a bedrock for developing altmetrics
#+END_NOTES

** Repositories
#+BEGIN_NOTES
Code that is being tracked and shared with a source control management system is usually stored in a "repository"

Members of a team have read and write access to this repository and the repository is usually used to coordinate changes made by different team members.

How exactly this is done is a whole other presentation (at least)
#+END_NOTES

* Git and Github
#+BEGIN_NOTES
Many of these solutions have been around for a long time,  

its only beein the last 5 to 10 years that web technologies have enabled some of the most interesting advances in source control management.

In particular with Git,  which a source control management system, 

and with Github,  which is a community built around and ontop of git.
#+END_NOTES
* Git 
(is a complicated)
#+BEGIN_NOTES
Git can be complicated -  and I'm not going to do more than give a 100,000 foot view here
#+END_NOTES

** Linus Torvalds
[[file:img/Linus.jpg]]
#+BEGIN_NOTES
Git is a source control management system created by this gentlman here

Linus Torvalds

relatively new source control management system,  it was created back in 2005.
#+END_NOTES
** Linus
:PROPERTIES:
:REVEAL_TRANS: fade
:END:

#+BEGIN_NOTES
For those who don't know - 

thats the same "Linu" as in "Linux"
#+END_NOTES

** Linux
:PROPERTIES:
:REVEAL_TRANS: fade
:END:
#+BEGIN_NOTES
Linus created the Linux kernl and is some times refered to as the "Benevolent Dictator for Life"

Git is used to manage many open source projects, including the Linux kernel which is (I believe)  around 25 million lines of code.
#+END_NOTES

** Git is free
#+BEGIN_NOTES
All thats really important to understand is that git is a robust, distributed source control management system

Its open source technology, anyone can download and run git.
#+END_NOTES

** Git is distributed
#+BEGIN_NOTES
Git is particularly revolutionary because it does not require a single centralized repository, 

each "clone" of a git repository contains the whole history of the repository 

each clone integrates patches from other developers (or researchers)

and push changes out to other developers (or researchers) 
#+END_NOTES



* Github 
"Build better software, together"
#+BEGIN_NOTES
Github is an online community that is built around and ontop of git. 

Over 4 million people use github to host and share their code with eachother.

Githubs model is innovative because they offer free git repository hosting as long as the code you share is public

#+END_NOTES

** Wait, public as in anyone can edit it?
#+BEGIN_NOTES
Wait.. public as in anyone can edit it?

No, only people who are given permission have write access to the repository,  

But everyone else (literally world wide)  has read access to materials tracked with a free github repository. 

#+END_NOTES


** Open Access
#+BEGIN_NOTES
Github is a world where "Open Access is the Default"

and I think you can make a pretty defensible argument that Github is the single largest open access publication platform that currently exists. 

In particular it provides a particularly fascinating feature that correlates nicely with research workflows.
#+END_NOTES


** SCMS are not just for Source Code
Local [[https://github.com/blog/1657-introducing-government-github-com][governments are already using]] Github \\
People are already publishing [[https://github.com/timchurches/meta-analyses/blob/master/benefits-of-reproducible-research/benefits-of-reproducible-research.md][articles]].

** Forking for Fun and Profit
#+BEGIN_NOTES

#+END_NOTES




* Oh yeah... The Metrics


* Final Thought


* Epilogue: Engaging with the presentation
"A mini-tutorail" 

* Parking lot                                                      :noexport:
** Open Access
**** Copyright exists to incentiveze creative works of non-trival effort
**** For scholars, incentive structure for publication is different
**** Attribution still a key factor
**** Prestige infrastructure 
** Software-carpentry
http://software-carpentry.org/
** Science Code Manifesto
http://sciencecodemanifesto.org/
**** Code
All source code written specifically to process data for a published paper must be available to the reviewers and readers of the paper.
**** Copyright
The copyright ownership and license of any released source code must be clearly stated.
**** Citation
Researchers who use or adapt science source code in their research must credit the code’s creators in resulting publications.
**** Credit
Software contributions must be included in systems of scientific assessment, credit, and recognition.
**** Curation
Source code must remain available, linked to related materials, for the useful lifetime of the publication.

** Modern Reproducible research
** Who is doing this?
**** Stanford Group
Jon Claerbout \\
David Donoho
**** Literate Programing
Donald Knuth
**** Bioinformatics and statistically intensive biology
**** Computational Statisticians and the R Community
Friedrich Leisch
**** Emacs and Org-Babel Community
**** Climate Code Foundation
Nick Barnes

#+BEGIN_NOTES
Relatively new group but with several high profile articles

Guy behind Science Code Manifesto
http://www.nature.com/news/2010/101013/full/467753a.html
#+END_NOTES
**** Elsiver?
http://www.executablepapers.com/



** Linus's Law
"given enough eyeballs, all bugs are shallow"; \\ 
or more formally: \\
"Given a large enough beta-tester and co-developer base, almost every problem will be characterized quickly and the fix will be obvious to someone." 
[citeRaymond]

** Government Github
** Provisions, Quid pro quos
+ Qualitative research,  research that lends itself to statistical analysis,  or requires any kind of data transformation before being analyzed.
** Reproducible research as bridge
+ Open Data provides direct access to data sources that have been created by all types of institutions (Gov, academic, private sector)
  - Published in many different ways, Raw data files,  API, SPARQL, sometimes this data is useful,  sometimes it is garbage
+ Open Access "advertises" the research,  but isn't the research itself.
  - Will need to do obligatory introduction to reproducible as foundation of modern science
  - Open Access is absolutely vital - it raises the visibility of a paper, research, and improves over all impact [citation?] [fn:1] 
+ The ACTUAL research is the transformed data, and the analysis - sometimes this means data cleanup,  sometimes this means large scale data transformation pipelines like in NLP and machine learning
  - reproducible research is the bridge between open data and open access it takes open data as an input, and produces papers as an output

  - shifting from a "publication as research" model the [data + transformation code + analysis + interpretation] as the research changes the meaning of open access to research

  - This begs an important question - how do we publish this kind of "document"

  - Not restrained by old journal model - can skip growing pains of online journal model (analogy of 1960's movies that were just filmed theater shows?)

  - Some have already discussed blogs, social networking etc as possible outcomes,  but metrics in this environment are still emerging

  - Metrics in the field of software engineering are pretty good though,

  - In broad strokes,  software engineers produce code and documentation,   researchers produce documentation (in the form of publications)  and code. 
    - software engineers even have a counterpart to Reproducible research - literate programming.
  - Key component of reproducible is access to the tools that produced to code and documentation - tie in open source

** Tools and Metrics
+ Github and github style metrics
+ Sweave
+ Emacs w/org-mode and org-babel
+ Things out there that are interesting,  but don't quite get the job done
  - Google Docs (highly collaborate, no version control,  no code integration) 
  - Authorea - (highly collaborative,  focus on academic's needs) 
  - runmycode.org ( code but no direct integration with "documentation", collaborative but not quite like github)
+ requirements for the ideal process
  - Open source tools (so barrier to access to those tools is only technical)
  - allows collaboration across researchers
  - embeds research (ie. code) directly into the documentation. 
  - version control (for archiving!) 


[fn:1] This could provide an interesting example for github style issue tracking, someone notes that this claim needs a citation,  author finds citation and adds it into the documents 

** Executable Papers and Literate Programing
*** Examples

#+BEGIN_SRC R :results graphics :file img/graph.png :exports results
# Define 2 vectors
cars <- c(1, 3, 6, 4, 9)
trucks <- c(2, 5, 4, 5, 12)

# Graph cars using a y axis that ranges from 0 to 12
plot(cars, type="o", col="blue", ylim=c(0,12))

# Graph trucks with red dashed line and square points
lines(trucks, type="o", pch=22, lty=2, col="red")

# Create a title with a red, bold/italic font
title(main="Autos", col.main="red", font.main=4)

#+END_SRC


https://github.com/kotfic/reproducible-research-presentation/blob/gh-pages/index.html#L590-592

** The Internet
*** TODO finish notes and trasition for this slide
#+BEGIN_NOTES

Printing press is the technology that enables the goals of reproducability (as Shirky poitns out - some 150 years later)
Internet and modern computing is the technology that creates the current threat to the =Credability= of the research process
But Technology can also help to solve the problem it is creating.
#+END_NOTES

** Computational Science
#+BEGIN_NOTES
While publishers and librarians come to grips with how to best utilize this new distribution mechanism (ie. Open Access)

Researchers have been struggling with how to ensure reproducibility in an environment where computation is becoming the lingua franca. 

#+END_NOTES

** Produce code and documentation
#+BEGIN_NOTES
For software developers documentation tends to take a back seat to code 

For researchers code (and data processesing) tends to take a back seat to documentation

and by documentation i mean a publishible paper. 

#+END_NOTES


* Tasks                                                            :noexport:
** Archive                                                         :ARCHIVE:
*** DONE find quote about the paper being an advertisement for the reserch
CLOSED: [2013-10-07 Mon 20:46]
:PROPERTIES:
:ARCHIVE_TIME: 2013-10-07 Mon 20:46
:END:
** DONE Read Claerbout's history of reproducible research
CLOSED: [2013-10-20 Sun 10:23]
[[http://sepwww.stanford.edu/data/media/public/sep//jon/reproducible.html][History of Reproducible Research]]

** DONE Scopus Claerbout's stuff on RR
CLOSED: [2013-10-20 Sun 10:23]
** TODO Read more about this Elsiver executible paper competition
http://www.executablepapers.com/
** TODO more information about Sweave
** TODO get more info about SPARQL
** TODO Does Authorea fit in here?
https://www.authorea.com/


* Papers to Read                                                   :noexport:
:PROPERTIES:
:ID:       487c95e9-eafe-46bd-882f-65cfc8aff174
:END:
+ [[id:cae658a7-daf9-44aa-b4d7-9fe44eaf907b][Stodden, V. :: Reproducible research: Tools and strategies for scientific computing (2012)]]
+ [[id:67c28701-807e-4fac-9f1b-cc5562ed0207][Stodden, Victoria :: Enabling reproducible research: licensing for scientific innovation (2009)]]
+ [[id:a54a04a8-aa72-45b5-bd93-6835e948357a][Knuth, Donald Ervin :: Literate programming (1984)]]

+ [[id:39da92be-f1e4-48e4-8efd-7711e53a958d][Hothorn, Torsten and Leisch, Friedrich :: Case studies in reproducibility (2011)]]
+ [[id:f4bdd44c-833e-4f7f-b752-3ee8bc92df9d][Peng, Roger D. :: Reproducible Research in Computational Science (2011)]]
+ [[id:358b6e1e-0898-4ef9-8074-4e869fa5774b][David Donoho and Arian Maleki and Inam Rahman and Morteza Shahram and Victoria Stodden :: 15 Years of Reproducible Research in Computational Harmonic Analysis (2008)]]
+ [[id:d7300347-3a70-4d70-aea6-e7781136c6b0][Schulte, E. and Davison, D. and Dye, T. and Dominik, C. :: A multi-language computing environment for literate programming and reproducible research (2012)]]


+ [[id:84ecf889-4619-4efc-bd45-fc48d026619b][Baiocchi, G. :: Reproducible research in computational economics: Guidelines, integrated approaches, and open source software (2007)]]
+ [[id:c7581914-7560-40a2-856e-15a987daa778][Van Gorp, P. and Mazanek, S. :: SHARE: A web portal for creating and sharing executable research papers (2011)]]
+ [[id:9c4dbbea-0442-4bf7-a52e-af8298698677][Mesirov, J.P. :: Accessible reproducible research (2010)]]     

+ [[id:53e934d9-9567-4cc6-aa83-4ebb7102763f][Vandewalle, P. and Kovacević, J. and Vetterli, M. :: Reproducible research in signal processing: What, why, and how (2009)]]

+ [[id:38a3e14d-d9ec-4b01-b315-a778caa59573][Fomel, S. and Claerbout, J.F. :: Guest editors' introduction: Reproducible research (2009)]]

M. Schwab, N. Karrenbach, J. Claerbout, Making scientific computations reproducible. Comput. Sci. Eng. 2, 61 (2000). Search Google Scholar
C. Laine, S. N. Goodman, M. E. Griswold, H. C. Sox, Reproducible research: Moving toward research the public can really trust. Ann. Intern. Med. 146, 450 (2007). Medline
G. King, Replication, Replication. PS: Polit. Sci. Polit. 28, 444 (1995). CrossRef

+ [[id:a9ab7962-3615-4b49-b460-45bd2c876c4c][Tomi Kauppinen and Giovana Mira de Espindola :: Linked Open Science-Communicating, Sharing and Evaluating Data, Methods and Results for Executable Papers  (2011)]]

** Nature articles
:PROPERTIES:
:ID:       642c4d43-1300-42ba-acc7-35c1d3e5901f
:END:
+ [[id:626ecf83-ad7f-429e-b036-84b10c1c4fe1][Begley, C. Glenn and Ellis, Lee M. :: {Drug development: Raise standards for preclinical cancer research} (2012)]]
+ [[id:066d8daf-ef7e-4efe-82c6-bf044e12e316][Mobley, , Aaron AND Linder, , Suzanne K. AND Braeuer, , Russell AND Ellis, , Lee M. AND Zwelling, , Leonard :: A Survey on Data Reproducibility in Cancer Research Provides Insights into Our Limited Ability to Translate Findings from the Laboratory to the Clinic (2013)]]






