#+Title: Reproducible research: open access, open data, open tools and metrics
#+Author: Christopher Kotfila
#+Email: ckotfila@albany.edu
#+OPTIONS: toc:nil num:nil

#+REVEAL_ROOT: revealjs/
#+REVEAL_HLEVEL: 1

* Introduction
Christopher Kotfila\\
PhD student - Information Science Department\\
College of Computing and Information\\
ckotfila@albany.edu \\
@kotfic
** Who Am I?
#+BEGIN_NOTES
Graduated last spring with an MSIS from here at UAlbany

Focused primarily on scholarly communication and open access

Last 10 years -amature/professional software developer

both in private sector doing web application development

and in academia as a research assistant.
#+END_NOTES
** That's a long title
Are you really going to talk about all that in 30 minutes?

#+BEGIN_NOTES
So the answer of course is no.

This talk is going to focus on reproducible research

cast it in the light of some problems that software engineers have been facing for a number of years

and then really what I'm really hoping is that I'll get a chance to show you some really cool tools that have emerged in the last 5 to 10 years

and then talk about how these tools related to open access and open data. 
#+END_NOTES

** Caveat 
#+BEGIN_QUOTE
"Release early, release often"[1]
#+END_QUOTE
 
#+BEGIN_HTML
<sup id="fn.1" style="font-size:18px;"> [1] Eric S. Raymond, The Cathedral and the Bazaar (1997) </sup>
#+END_HTML

#+BEGIN_NOTES
So there is a relatively well established philosophy in software development "Release early release often"

In software this means,  get your program out there as soon as possible and let people start giving you feedback

This presentation emerges from a number of threads that have been stewing for the last couple of years

The ideas here are still a little rough,  in true Open Source fashion,  I hope you'll help me refine them. 

#+END_NOTES
* An Example from personal experience
#+BEGIN_NOTES
So - I began working as a research assistant here at Albany at the beginning of this summer

The work I'm learning to do involves writing computer programs to to pull structured information out of unstructured medical discharge summaries.  

There are a lot of interesting and practical applications for work like this

tracking patient outcomes for instance

identifying systematic issues at hospitals or with health care processes - lots of stuff.

This is done primarily with natural language process tools (ie.  computer programs and processes) 

As an initial exercize I set out to reproduce a well performing system in a particular challenge that tried to identify whether patients had obesity based on the free-form text in their medical record.

#+END_NOTES
* The idea was...
** reproduce the system based on the description in the paper,

** try to identify systematic errors
** correct those errors
** publish in a prestigious journal
** get a tenure-track position at a respected university
** live happily ever afer

* So It turns out...
#+BEGIN_NOTES
You can probably guess from the title of the talk,  this did not go as planned.

The system itself is gone - emailed the authors,  they were extreamly helpful

but it was stored on a server they no longer have access too.

the system, the solution in its most tangible form, is gone.

This brings us to

#+END_NOTES



* Reproducibility
#+BEGIN_NOTES
Fundimentally rooted in scientific skepticism. 

Findings may be interesting - but if they can't be reproduced by third parties in normalalized settings 

Then we're obligated to "take the word of" researchers 

rather than building on a firm foundation of findings that meet the bar of reproducibility
#+END_NOTES

* Reproducibility creates Credibility 

* Technology enables reproducibility 
#+BEGIN_NOTES
Technology has traditionally enabled reproducibility
#+END_NOTES
* 
[[file:img/402px-1665_phil_trans_vol_i_title.png]]

#+BEGIN_NOTES
our modern day style of scholarly communication really begins with the introduction of the printing press into the scholarly process

The wide distribution of ideas allowed for scholars across Europe to test and refine the ideas of their peers. 

Today we face a new distribution mechanism: 

#+END_NOTES


* The Internet
** TODO finish notes and trasition for this slide
#+BEGIN_NOTES

Printing press is the technology that enables the goals of reproducability (as Shirky poitns out - some 150 years later)
Internet and modern computing is the technology that creates the current threat to the =Credability= of the research process
But Technology can also help to solve the problem it is creating.
#+END_NOTES

* Computational Science
#+BEGIN_NOTES
While publishers and librarians come to grips with how to best utilize this new distribution mechanism (ie. Open Access)

Researchers have been struggling with how to ensure reproducibility in an environment where computation is becoming the lingua franca. 

#+END_NOTES


* The Open Science Pipeline 
#+BEGIN_NOTES
Really reproducible research spans all the steps between a data source and a publiction. 

All the steps involved in obtaining,  scrubing, modeling, interpreting and presenting data. 

This doesn't HAVE to be in the context of an open data and open access 

BUT - in this context open reproducible research brings end-to-end transparency to the entire process.


#+END_NOTES
+ Open Data
+ Reproducible Research
+ Open Access


* Open Reproducible Research
#+BEGIN_NOTES
Open Data and Open Access alone are insufficient - Open Reproducible research is a vital part of the pipeline

Those interested in advocating for Open Access should be paying very close attention to the reproducible research movement

soon papers won't be the only thing researchers want and need access too.
#+END_NOTES


* 
#+BEGIN_QUOTE
“The idea is: An article about computational science in a scientific
publication is not the scholarship itself, it is merely advertising of the
scholarship. The actual scholarship is the complete ... set of
instructions [and data] which generated the figures.”
David Donoho, 1998.
#+END_QUOTE

#+BEGIN_NOTES
David Donoho is one of the reseachers over at Stanford who has been actively involved with the reproducibility movement for decades

As Donoho puts it:

His quote here really captures the kind of reproducibility that is creating what some are describing as a credibility crisis
#+END_NOTES

* A state of "Crisis"
+ Begley, C. Glenn and Ellis, Lee M. Drug development: Raise standards for preclinical cancer research, Nature (2012)
+ AAAS (2011). AAAS annual meeting: Workshop on the digitization of science: Repro-ducibility and interdisciplinary knowledge transfer.
+ AMP (2011). Applied mathematics perspectives workshop on reproducible research: Toolsand strategies for scientific computing applied mathematics perspectives.
+ SIAM-CSE (2011). SIAM conference on computational science & engineering workshop onverifiable, reproducible computational science.
+ SIAM-Geo (2011). SIAM geosciences workshop on reproducible science and open-sourcesoftware in the geosciences
+ NSF (2010). National science foundation workshop on changing the conduct of science inthe information age summary.
+ ENAR (2011). Research ethics in biostatistics: Invited panel discussion at ENAR 2011 onthe biostatistician’s role in reproducible research.
+ Yale Law School Round Table on Data and Code Sharing (2009)

#+BEGIN_NOTES
Many of these conferences, papers, and authors have proposed tentative solutions that span a spectrum 

from technical implementations of code repositories 

to policy recommendations that seek to support socio-cultural change in the academic community.
#+END_NOTES


* Some Examples
+ [[http://runmycode.org/][RunMyCode.org]]
+ [[http://www.stat.uni-muenchen.de/~leisch/Sweave/][Sweave]]
+ [[https://openscienceframework.org/][Open Science Framework]]
+ [[http://www.stanford.edu/~vcs/Papers.html][Victoria Stodden's work]]

#+BEGIN_NOTES
Of course there are many many more examples 

but what I'd like to humbly suggest,  is that at least from a technical perspective,  this is already a solved problem.

And - that there are STRONG examples in the open source software development community

for how resolve the socio-cultural aspects of the computational reproducibility problem.

#+END_NOTES


* Open Source Software Developers
#+BEGIN_NOTES
Reproducibility is (arguably) the number one concern of open source software developers.

As an software developer,  if the code i write and run on my system 

doesn't run on your system

my code is broken.

#+END_NOTES


* Open Source Software Developers and Researchers 
(have a lot in common)
** Highly specialized
** Experts in their area
** Collaborate frequently
Usually working on teams that are \\
geographically disparate  \\ 
culturally diverse
** Produce complex processes that 
+ obtain 
+ scrub
+ explore
+ model 
+ interpret
+ and display data
** Code and Documentation
#+BEGIN_NOTES
For software developers documentation tends to take a back seat to code 

For researchers code (and data processesing) tends to take a back seat to documentation

and by documentation i mean a publishible paper. 

#+END_NOTES




* Tools
#+BEGIN_NOTES
Software developers have been faced with the reproducibility problem for decades

because the success of an open software development project is BASED on its ability to be reproduced across many systems

open source software DEVELOPERS have produced tools that are optimized to ease this distribution.

Because of the similarities between open source software developers and researchers many of these tools can be recast in light of the research process.
#+END_NOTES

* Source Control Management Systems
#+BEGIN_NOTES
The most germane tools I want to talk about are in the category of Source Control
#+END_NOTES
** Maybe you've seen this problem before
#+ATTR_REVEAL: :frag roll-in
+ Draft paper.docx
#+ATTR_REVEAL: :frag roll-in
+ Draft paper2.docx
#+ATTR_REVEAL: :frag roll-in
+ Draft paper2_old.docx
#+ATTR_REVEAL: :frag roll-in
+ Draft paper3_revisions_from_dla.docx
#+ATTR_REVEAL: :frag roll-in
+ Final submitted.docx
#+ATTR_REVEAL: :frag roll-in
+ Final submitted revised.docx
#+BEGIN_NOTES
Keeping track of changes in a single document is hard

Keeping track of changes from a group of authors and reviewers in a single document is even harder

Magnify that difficulty by the thousands and sometimes tens of thousands of documents in an software development project

and you might as well pack up and go home
#+END_NOTES


** *Who* did *what*, *when* and *why*?
#+BEGIN_NOTES
The only way to manage this effectively is build a system that tracks WHO did WHAT WHEN, and most importaintly WHY.

Here is an example
#+END_NOTES
An Example of a [[https://github.com/kotfic/reproducible-research-presentation/commit/04ff60559adcf31f627f909c2cc4e00f1c564509]["Commit"]]

** Diffs and Patches
#+BEGIN_NOTES
Tracking this information in such excrutiating detail provides interesting possibilities

For one it allows you to pass the changes that you make to a document easily to someone else

Source Control Management systems will (mostly)  seamlessly integrate your changes into other people's copy of your document.

additionally this kind of specificity allows for profound archiving possibilities and provides a bedrock for developing altmetrics
#+END_NOTES

** Repositories
#+BEGIN_NOTES
Code that is being tracked and shared with a source control management system is usually stored in a "repository"

Members of a team have read and write access to this repository and the repository is usually used to coordinate changes made by different team members.

How exactly this is done is a whole other presentation (at least)
#+END_NOTES

* Git and Github
#+BEGIN_NOTES
Many of these solutions have been around for a long time,  

its only beein the last 5 to 10 years that web technologies have enabled some of the most interesting advances in source control management.

In particular with Git,  which a source control management system, 

and with Github,  which is a community built around and ontop of git.
#+END_NOTES
* Git 
(is a complicated)
#+BEING_NOTES
Git can be complicated -  and I'm not going to do more than give a 100,000 foot view here
#+END_NOTES

** Linus Torvalds
[[file:img/Linus.jpg]]
#+BEGIN_NOTES
Git is a source control management system created by this gentlman here

Linus Torvalds

relatively new source control management system,  it was created back in 2005.
#+END_NOTES
** Linus
#+BEGIN_NOTES
For those who don't know - 

thats the same "Linu" as in "Linux"
#+END_NOTES

** Linux
#+BEGIN_NOTES
Linus created the Linux kernl and is some times refered to as the "Benevolent Dictator for Life"

Git is used to manage many open source projects, including the Linux kernel which is (I believe)  around 25 million lines of code.
#+END_NOTES

** Git is free
#+BEGIN_NOTES
All thats really important to understand is that git is a robust, distributed source control management system

Its open source technology, anyone can download and run git.
#+END_NOTES

** Git is distributed
#+BEGIN_NOTES
Git is particularly revolutionary because it does not require a single centralized repository, 

each "clone" of a git repository contains the whole history of the repository 

each clone integrates patches from other developers (or researchers)

and push changes out to other developers (or researchers) 
#+END_NOTES



* Github 
#+BEGIN_NOTES
Github is an online community that 
#+END_NOTES
** SCMS are not just for Source Code
Local [[https://github.com/blog/1657-introducing-government-github-com][governments are already using]] Github \\
People are already publishing [[https://github.com/timchurches/meta-analyses/blob/master/benefits-of-reproducible-research/benefits-of-reproducible-research.md][articles]].


** Open Access
#+BEGIN_NOTES
I think you can make a defensible argument that Github is the single largest open access publication platform that currently exists. 

In particular it provides a particularly fascinating feature that correlates nicely with research workflows.

#+END_NOTES

** Forking for Fun and Profit
#+BEING_NOTES

#+END_NOTES

* Executable Papers and Literate Programing
** Examples

#+BEGIN_SRC R :results graphics :file img/graph.png :exports results
# Define 2 vectors
cars <- c(1, 3, 6, 4, 9)
trucks <- c(2, 5, 4, 5, 12)

# Graph cars using a y axis that ranges from 0 to 12
plot(cars, type="o", col="blue", ylim=c(0,12))

# Graph trucks with red dashed line and square points
lines(trucks, type="o", pch=22, lty=2, col="red")

# Create a title with a red, bold/italic font
title(main="Autos", col.main="red", font.main=4)

#+END_SRC


https://github.com/kotfic/reproducible-research-presentation/blob/gh-pages/index.html#L590-592


* Oh yeah... The Metrics


* Final Thought


* Epilogue: Engaging with the presentation
"A mini-tutorail" 

* Parking lot                                                      :noexport:
** Open Access
**** Copyright exists to incentiveze creative works of non-trival effort
**** For scholars, incentive structure for publication is different
**** Attribution still a key factor
**** Prestige infrastructure 
** Software-carpentry
http://software-carpentry.org/
** Science Code Manifesto
http://sciencecodemanifesto.org/
**** Code
All source code written specifically to process data for a published paper must be available to the reviewers and readers of the paper.
**** Copyright
The copyright ownership and license of any released source code must be clearly stated.
**** Citation
Researchers who use or adapt science source code in their research must credit the code’s creators in resulting publications.
**** Credit
Software contributions must be included in systems of scientific assessment, credit, and recognition.
**** Curation
Source code must remain available, linked to related materials, for the useful lifetime of the publication.

** Modern Reproducible research
** Who is doing this?
**** Stanford Group
Jon Claerbout \\
David Donoho
**** Literate Programing
Donald Knuth
**** Bioinformatics and statistically intensive biology
**** Computational Statisticians and the R Community
Friedrich Leisch
**** Emacs and Org-Babel Community
**** Climate Code Foundation
Nick Barnes

#+BEING_NOTES
Relatively new group but with several high profile articles

Guy behind Science Code Manifesto
http://www.nature.com/news/2010/101013/full/467753a.html
#+END_NOTES
**** Elsiver?
http://www.executablepapers.com/




** Linus's Law
"given enough eyeballs, all bugs are shallow"; \\ 
or more formally: \\
"Given a large enough beta-tester and co-developer base, almost every problem will be characterized quickly and the fix will be obvious to someone." 
[citeRaymond]

** Government Github
** Provisions, Quid pro quos
+ Qualitative research,  research that lends itself to statistical analysis,  or requires any kind of data transformation before being analyzed.
** Reproducible research as bridge
+ Open Data provides direct access to data sources that have been created by all types of institutions (Gov, academic, private sector)
  - Published in many different ways, Raw data files,  API, SPARQL, sometimes this data is useful,  sometimes it is garbage
+ Open Access "advertises" the research,  but isn't the research itself.
  - Will need to do obligatory introduction to reproducible as foundation of modern science
  - Open Access is absolutely vital - it raises the visibility of a paper, research, and improves over all impact [citation?] [fn:1] 
+ The ACTUAL research is the transformed data, and the analysis - sometimes this means data cleanup,  sometimes this means large scale data transformation pipelines like in NLP and machine learning
  - reproducible research is the bridge between open data and open access it takes open data as an input, and produces papers as an output

  - shifting from a "publication as research" model the [data + transformation code + analysis + interpretation] as the research changes the meaning of open access to research

  - This begs an important question - how do we publish this kind of "document"

  - Not restrained by old journal model - can skip growing pains of online journal model (analogy of 1960's movies that were just filmed theater shows?)

  - Some have already discussed blogs, social networking etc as possible outcomes,  but metrics in this environment are still emerging

  - Metrics in the field of software engineering are pretty good though,

  - In broad strokes,  software engineers produce code and documentation,   researchers produce documentation (in the form of publications)  and code. 
    - software engineers even have a counterpart to Reproducible research - literate programming.
  - Key component of reproducible is access to the tools that produced to code and documentation - tie in open source

** Tools and Metrics
+ Github and github style metrics
+ Sweave
+ Emacs w/org-mode and org-babel
+ Things out there that are interesting,  but don't quite get the job done
  - Google Docs (highly collaborate, no version control,  no code integration) 
  - Authorea - (highly collaborative,  focus on academic's needs) 
  - runmycode.org ( code but no direct integration with "documentation", collaborative but not quite like github)
+ requirements for the ideal process
  - Open source tools (so barrier to access to those tools is only technical)
  - allows collaboration across researchers
  - embeds research (ie. code) directly into the documentation. 
  - version control (for archiving!) 


[fn:1] This could provide an interesting example for github style issue tracking, someone notes that this claim needs a citation,  author finds citation and adds it into the documents 


* Tasks                                                            :noexport:
** Archive                                                         :ARCHIVE:
*** DONE find quote about the paper being an advertisement for the reserch
CLOSED: [2013-10-07 Mon 20:46]
:PROPERTIES:
:ARCHIVE_TIME: 2013-10-07 Mon 20:46
:END:
** DONE Read Claerbout's history of reproducible research
CLOSED: [2013-10-20 Sun 10:23]
[[http://sepwww.stanford.edu/data/media/public/sep//jon/reproducible.html][History of Reproducible Research]]

** DONE Scopus Claerbout's stuff on RR
CLOSED: [2013-10-20 Sun 10:23]
** TODO Read more about this Elsiver executible paper competition
http://www.executablepapers.com/
** TODO more information about Sweave
** TODO get more info about SPARQL
** TODO Does Authorea fit in here?
https://www.authorea.com/


* Papers to Read                                                   :noexport:
:PROPERTIES:
:ID:       487c95e9-eafe-46bd-882f-65cfc8aff174
:END:
+ [[id:cae658a7-daf9-44aa-b4d7-9fe44eaf907b][Stodden, V. :: Reproducible research: Tools and strategies for scientific computing (2012)]]
+ [[id:67c28701-807e-4fac-9f1b-cc5562ed0207][Stodden, Victoria :: Enabling reproducible research: licensing for scientific innovation (2009)]]
+ [[id:a54a04a8-aa72-45b5-bd93-6835e948357a][Knuth, Donald Ervin :: Literate programming (1984)]]

+ [[id:39da92be-f1e4-48e4-8efd-7711e53a958d][Hothorn, Torsten and Leisch, Friedrich :: Case studies in reproducibility (2011)]]
+ [[id:f4bdd44c-833e-4f7f-b752-3ee8bc92df9d][Peng, Roger D. :: Reproducible Research in Computational Science (2011)]]
+ [[id:358b6e1e-0898-4ef9-8074-4e869fa5774b][David Donoho and Arian Maleki and Inam Rahman and Morteza Shahram and Victoria Stodden :: 15 Years of Reproducible Research in Computational Harmonic Analysis (2008)]]
+ [[id:d7300347-3a70-4d70-aea6-e7781136c6b0][Schulte, E. and Davison, D. and Dye, T. and Dominik, C. :: A multi-language computing environment for literate programming and reproducible research (2012)]]


+ [[id:84ecf889-4619-4efc-bd45-fc48d026619b][Baiocchi, G. :: Reproducible research in computational economics: Guidelines, integrated approaches, and open source software (2007)]]
+ [[id:c7581914-7560-40a2-856e-15a987daa778][Van Gorp, P. and Mazanek, S. :: SHARE: A web portal for creating and sharing executable research papers (2011)]]
+ [[id:9c4dbbea-0442-4bf7-a52e-af8298698677][Mesirov, J.P. :: Accessible reproducible research (2010)]]     

+ [[id:53e934d9-9567-4cc6-aa83-4ebb7102763f][Vandewalle, P. and Kovacević, J. and Vetterli, M. :: Reproducible research in signal processing: What, why, and how (2009)]]

+ [[id:38a3e14d-d9ec-4b01-b315-a778caa59573][Fomel, S. and Claerbout, J.F. :: Guest editors' introduction: Reproducible research (2009)]]

M. Schwab, N. Karrenbach, J. Claerbout, Making scientific computations reproducible. Comput. Sci. Eng. 2, 61 (2000). Search Google Scholar
C. Laine, S. N. Goodman, M. E. Griswold, H. C. Sox, Reproducible research: Moving toward research the public can really trust. Ann. Intern. Med. 146, 450 (2007). Medline
G. King, Replication, Replication. PS: Polit. Sci. Polit. 28, 444 (1995). CrossRef

+ [[id:a9ab7962-3615-4b49-b460-45bd2c876c4c][Tomi Kauppinen and Giovana Mira de Espindola :: Linked Open Science-Communicating, Sharing and Evaluating Data, Methods and Results for Executable Papers  (2011)]]

** Nature articles
:PROPERTIES:
:ID:       642c4d43-1300-42ba-acc7-35c1d3e5901f
:END:
+ [[id:626ecf83-ad7f-429e-b036-84b10c1c4fe1][Begley, C. Glenn and Ellis, Lee M. :: {Drug development: Raise standards for preclinical cancer research} (2012)]]
+ [[id:066d8daf-ef7e-4efe-82c6-bf044e12e316][Mobley, , Aaron AND Linder, , Suzanne K. AND Braeuer, , Russell AND Ellis, , Lee M. AND Zwelling, , Leonard :: A Survey on Data Reproducibility in Cancer Research Provides Insights into Our Limited Ability to Translate Findings from the Laboratory to the Clinic (2013)]]






